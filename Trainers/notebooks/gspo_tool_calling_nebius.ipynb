{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSPO Training for Tool-Calling\n",
    "\n",
    "**Portable notebook for Unsloth Docker + any NVIDIA GPU**\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "### Option 1: Unsloth Docker (Recommended)\n",
    "```bash\n",
    "# On any GPU cloud (Nebius VM, RunPod, Lambda, etc.) or local:\n",
    "docker run -d -e JUPYTER_PASSWORD=\"your_password\" \\\n",
    "  -p 8888:8888 \\\n",
    "  -v $(pwd)/work:/workspace/work \\\n",
    "  --gpus all \\\n",
    "  unsloth/unsloth\n",
    "```\n",
    "Then open `http://localhost:8888` and upload this notebook.\n",
    "\n",
    "### Option 2: Nebius Managed JupyterLab\n",
    "Use their JupyterLab service and run the install cell below (takes ~3 min).\n",
    "\n",
    "---\n",
    "\n",
    "## What is GSPO?\n",
    "\n",
    "**GSPO (Group Sequence Policy Optimization)** generates completions during training and optimizes using custom reward functions.\n",
    "\n",
    "| Method | Best For | Tool-Calling Use Case |\n",
    "|--------|----------|----------------------|\n",
    "| **SFT** | Teaching new skills | Initial tool syntax |\n",
    "| **KTO** | Refining preferences | Good vs bad choices |\n",
    "| **GSPO** | Reward optimization | Tool selection quality |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected!\")\n",
    "\n",
    "# Detect environment\n",
    "IN_UNSLOTH_DOCKER = os.path.exists(\"/workspace/unsloth-notebooks\")\n",
    "IN_NEBIUS = os.path.exists(os.path.expanduser(\"~/persistent\"))\n",
    "\n",
    "print(f\"\\nUnsloth Docker: {'Yes' if IN_UNSLOTH_DOCKER else 'No'}\")\n",
    "print(f\"Nebius JupyterLab: {'Yes' if IN_NEBIUS else 'No'}\")\n",
    "\n",
    "# Set work directory\n",
    "if IN_UNSLOTH_DOCKER:\n",
    "    WORK_DIR = \"/workspace/work\"\n",
    "elif IN_NEBIUS:\n",
    "    WORK_DIR = os.path.expanduser(\"~/persistent\")\n",
    "else:\n",
    "    WORK_DIR = os.getcwd()\n",
    "\n",
    "OUTPUT_DIR = os.path.join(WORK_DIR, \"GSPO_Training\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nWork dir: {WORK_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")\n",
    "\n",
    "# Disk space\n",
    "total, used, free = shutil.disk_usage(WORK_DIR)\n",
    "print(f\"Disk: {free // (2**30)} GB free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (ONLY if NOT in Unsloth Docker)\n",
    "# Skip this cell if using unsloth/unsloth Docker image\n",
    "\n",
    "if not IN_UNSLOTH_DOCKER:\n",
    "    print(\"Installing Unsloth (this takes ~3 minutes)...\")\n",
    "    !pip install \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\" -q\n",
    "    !pip install -U trl peft datasets accelerate bitsandbytes xformers triton -q\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(\"Unsloth Docker detected - skipping install (pre-installed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HuggingFace Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check environment variables\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\") or os.environ.get(\"HF_API_KEY\")\n",
    "\n",
    "# Try .env files\n",
    "if not HF_TOKEN:\n",
    "    for path in [f\"{WORK_DIR}/.env\", os.path.expanduser(\"~/.env\"), \".env\"]:\n",
    "        if os.path.exists(path):\n",
    "            with open(path) as f:\n",
    "                for line in f:\n",
    "                    if line.startswith((\"HF_TOKEN=\", \"HF_API_KEY=\")):\n",
    "                        HF_TOKEN = line.split(\"=\", 1)[1].strip().strip('\"\\'')\n",
    "                        print(f\"Loaded from: {path}\")\n",
    "                        break\n",
    "            if HF_TOKEN: break\n",
    "\n",
    "# Manual fallback\n",
    "if not HF_TOKEN:\n",
    "    print(\"No HF_TOKEN found. Uncomment below to set:\")\n",
    "    # HF_TOKEN = \"hf_your_token_here\"\n",
    "\n",
    "# Validate\n",
    "hf_user = None\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    from huggingface_hub import HfApi\n",
    "    try:\n",
    "        hf_user = HfApi().whoami(token=HF_TOKEN)[\"name\"]\n",
    "        print(f\"Authenticated: {hf_user}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Token invalid: {e}\")\n",
    "else:\n",
    "    print(\"HF_TOKEN not set - upload disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these values\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_NAME = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "\n",
    "DATASET_NAME = \"professorsynapse/claudesidian-behaviors-merged\"\n",
    "DATASET_FILE = \"behavior_gspo_v1.3.jsonl\"\n",
    "\n",
    "OUTPUT_MODEL_NAME = \"nexus-tools-gspo\"\n",
    "\n",
    "# LoRA config\n",
    "LORA_R = 32\n",
    "LORA_ALPHA = 64\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "# Training config\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUM = 4\n",
    "LEARNING_RATE = 5e-6\n",
    "NUM_GENERATIONS = 4\n",
    "MAX_NEW_TOKENS = 512\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Dataset: {DATASET_NAME}/{DATASET_FILE}\")\n",
    "print(f\"Effective batch: {BATCH_SIZE * GRAD_ACCUM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "print(f\"Loaded: {sum(p.numel() for p in model.parameters()):,} params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    ")\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable: {trainable:,} params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, data_files=DATASET_FILE, split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} examples\")\n",
    "print(f\"Sample tool: {dataset[0]['ground_truth_tool']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "CONTEXT_FIELDS = [\"sessionId\", \"workspaceId\", \"sessionDescription\",\n",
    "                  \"sessionMemory\", \"toolContext\", \"primaryGoal\", \"subgoal\"]\n",
    "\n",
    "def extract_tool_call(text):\n",
    "    \"\"\"Extract tool name and args from output.\"\"\"\n",
    "    # Pattern 1: tool_call: name\\narguments: {...}\n",
    "    m = re.search(r'tool_call:\\s*(\\w+)\\s*\\narguments:\\s*({.+?})', text, re.DOTALL)\n",
    "    if m:\n",
    "        try: return m.group(1), json.loads(m.group(2))\n",
    "        except: return m.group(1), {}\n",
    "    \n",
    "    # Pattern 2: {\"name\": \"...\", \"arguments\": ...}\n",
    "    m = re.search(r'\"name\"\\s*:\\s*\"([^\"]+)\".*?\"arguments\"\\s*:\\s*({.+?})', text, re.DOTALL)\n",
    "    if m:\n",
    "        try: return m.group(1), json.loads(m.group(2).replace('\\\\\"', '\"'))\n",
    "        except: return m.group(1), {}\n",
    "    \n",
    "    # Pattern 3: Just tool name\n",
    "    m = re.search(r'(\\w+Manager_\\w+|\\w+Librarian_\\w+)', text)\n",
    "    return (m.group(1), {}) if m else (None, None)\n",
    "\n",
    "\n",
    "def combined_reward(completions, prompts, ground_truth_tool, **kw):\n",
    "    \"\"\"Combined reward (max 2.0): tool(1.0) + json(0.3) + context(0.5) + format(0.2)\"\"\"\n",
    "    rewards = []\n",
    "    for c in completions:\n",
    "        text = c[0][\"content\"] if isinstance(c, list) else c\n",
    "        tool, args = extract_tool_call(text)\n",
    "        r = 0.0\n",
    "        \n",
    "        # Tool selection (+1.0 exact, +0.3 same family)\n",
    "        if tool == ground_truth_tool:\n",
    "            r += 1.0\n",
    "        elif tool and ground_truth_tool and tool.split('_')[0] == ground_truth_tool.split('_')[0]:\n",
    "            r += 0.3\n",
    "        \n",
    "        # JSON structure (+0.3)\n",
    "        if args and isinstance(args, dict):\n",
    "            r += 0.3\n",
    "        \n",
    "        # Context completeness (up to +0.5)\n",
    "        if args and \"context\" in args and isinstance(args.get(\"context\"), dict):\n",
    "            ctx = args[\"context\"]\n",
    "            present = sum(1 for f in CONTEXT_FIELDS if ctx.get(f))\n",
    "            r += (present / len(CONTEXT_FIELDS)) * 0.5\n",
    "        \n",
    "        # Format (+0.2)\n",
    "        if re.search(r'tool_call|function|arguments|Manager_|Librarian_', text, re.I):\n",
    "            r += 0.2\n",
    "        \n",
    "        rewards.append(r)\n",
    "    return rewards\n",
    "\n",
    "# Test\n",
    "test = [[{\"content\": 'tool_call: vaultManager_list\\narguments: {\"context\": {\"sessionId\": \"x\", \"workspaceId\": \"x\", \"sessionDescription\": \"x\", \"sessionMemory\": \"x\", \"toolContext\": \"x\", \"primaryGoal\": \"x\", \"subgoal\": \"x\"}}'}]]\n",
    "print(f\"Test reward: {combined_reward(test, [''], 'vaultManager_list')[0]:.2f} / 2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set chat template\n",
    "MISTRAL_TEMPLATE = \"\"\"{{ bos_token }}{% for message in messages %}{% if message['role'] == 'system' %}{% if loop.index == 1 %}{{ message['content'] + ' ' }}{% endif %}{% elif message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' ' + message['content'] + eos_token }}{% endif %}{% endfor %}\"\"\"\n",
    "\n",
    "if tokenizer.chat_template is None and 'mistral' in MODEL_NAME.lower():\n",
    "    tokenizer.chat_template = MISTRAL_TEMPLATE\n",
    "\n",
    "def format_example(ex):\n",
    "    return {\n",
    "        \"prompt\": tokenizer.apply_chat_template(ex[\"prompt\"], tokenize=False, add_generation_prompt=True),\n",
    "        \"ground_truth_tool\": ex[\"ground_truth_tool\"],\n",
    "        \"ground_truth_args\": json.dumps(ex[\"ground_truth_args\"], default=str) if ex[\"ground_truth_args\"] else \"{}\"\n",
    "    }\n",
    "\n",
    "formatted_dataset = dataset.map(format_example, remove_columns=[\"prompt\"])\n",
    "print(f\"Formatted {len(formatted_dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Setup Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from unsloth import is_bfloat16_supported\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(OUTPUT_DIR, timestamp)\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=run_dir,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    num_generations=NUM_GENERATIONS,\n",
    "    max_completion_length=MAX_NEW_TOKENS,\n",
    "    importance_sampling_level=\"sequence\",  # GSPO\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=1,\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    optim=\"adamw_8bit\",\n",
    "    logging_steps=5,\n",
    "    save_steps=50,\n",
    "    save_total_limit=3,\n",
    "    seed=42,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=combined_reward,\n",
    "    args=training_args,\n",
    "    train_dataset=formatted_dataset,\n",
    ")\n",
    "\n",
    "print(f\"Trainer ready! Output: {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Check for resume\n",
    "checkpoints = sorted(glob.glob(f\"{run_dir}/checkpoint-*\"))\n",
    "resume_from = max(checkpoints, key=lambda x: int(x.split(\"-\")[-1])) if checkpoints else None\n",
    "if resume_from:\n",
    "    print(f\"Resuming from: {resume_from}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STARTING GSPO TRAINING\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=resume_from)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save & Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally\n",
    "final_dir = os.path.join(run_dir, \"final_model\")\n",
    "model.save_pretrained(final_dir)\n",
    "tokenizer.save_pretrained(final_dir)\n",
    "print(f\"Saved: {final_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload LoRA to HuggingFace\n",
    "if hf_user and HF_TOKEN:\n",
    "    repo = f\"{hf_user}/{OUTPUT_MODEL_NAME}\"\n",
    "    model.push_to_hub(repo, token=HF_TOKEN)\n",
    "    tokenizer.push_to_hub(repo, token=HF_TOKEN)\n",
    "    print(f\"LoRA: https://huggingface.co/{repo}\")\n",
    "else:\n",
    "    print(\"Set HF_TOKEN to upload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload merged 16-bit (optional)\n",
    "if hf_user and HF_TOKEN:\n",
    "    model.push_to_hub_merged(\n",
    "        f\"{hf_user}/{OUTPUT_MODEL_NAME}-merged\",\n",
    "        tokenizer,\n",
    "        save_method=\"merged_16bit\",\n",
    "        token=HF_TOKEN,\n",
    "    )\n",
    "    print(f\"Merged: https://huggingface.co/{hf_user}/{OUTPUT_MODEL_NAME}-merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload GGUF quantizations (optional)\n",
    "if hf_user and HF_TOKEN:\n",
    "    model.push_to_hub_gguf(\n",
    "        f\"{hf_user}/{OUTPUT_MODEL_NAME}\",\n",
    "        tokenizer,\n",
    "        quantization_method=[\"q4_k_m\", \"q5_k_m\", \"q8_0\"],\n",
    "        token=HF_TOKEN,\n",
    "    )\n",
    "    print(f\"GGUF: https://huggingface.co/{hf_user}/{OUTPUT_MODEL_NAME} (Files tab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "**Local model:** `{OUTPUT_DIR}/{timestamp}/final_model/`\n",
    "\n",
    "**Next steps:**\n",
    "1. Test with LM Studio or Ollama\n",
    "2. Compare GSPO vs SFT on tool selection\n",
    "3. Iterate on reward functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
